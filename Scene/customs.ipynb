{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# hardware and OS\n",
    "All steps are run on a ml.p3.2xlarge Amazon SageMaker Notebook instance.\n",
    "\n",
    "Select kernel :conda_pytorch_p36. Jump directly to Install the requirements."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Environment setup\n",
    "before installing anything related to this project, first you need a version of PyTorch compatible with your GPU settings\n",
    "\n",
    "with the 2 line script below you can check if your environment is ok."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! wget --quiet \"https://raw.githubusercontent.com/pytorch/pytorch/master/torch/utils/collect_env.py\"\n",
    "! python collect_env.py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- first, check that your computer detect your graphic card ``GPU 0: ...``\n",
    "- second, you need a driver to use your GPU for any application: ``Nvidia driver version: ...``\n",
    "- third, you need some libraries to run any data science algorith on your GPU: ``cuDNN version: ...`` and ``CUDA runtime version: ...``\n",
    "- fourth, you need to install Pytorch after having all the things above so that Pytorch is built using the CUDA library: ``PyTorch version: 1.5.0+cu101`` and ``CUDA used to build PyTorch: 10.1``\n",
    "- Finally, if your are on windows, you might also need ``Microsoft Visual C++ 14.0``\n",
    "\n",
    "If any of these are missing, the project setup will probably fail somewhere. Below are the instruction to fix your environment."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!gcc --version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Driver\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# this command must work otherwise check the symLink /usr/local/cuda\n",
    "!nvcc --version"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CUDA\n",
    "Note that each version of CUDA has a minimum requirement concerning the version of the driver\n",
    "\n",
    "\n",
    "cuda toolkit: https://developer.nvidia.com/cuda-10.1-download-archive-base?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal\n",
    "example of thing you should install XD\n",
    "```\n",
    "wget https://developer.nvidia.com/compute/cuda/10.1/Prod/local_installers/cuda_10.1.105_418.39_linux.run\n",
    "sh cuda_10.1.105_418.39_linux.run\n",
    "```\n",
    "\n",
    "## libnccl\n",
    "Nvidia NCCL can be downloaded from: https://developer.nvidia.com/nccl/nccl-download (you need to create a free account)\n",
    "\n",
    "## libcudnn\n",
    "do not download ``libcudnn-dev``\n",
    "\n",
    "then install it using this command ``dpkg -i libcudnn7_7.6.5.32-1+cuda10.1_amd64.deb``\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pytorch\n",
    "Get the command line that fits your hardware on this web site: https://pytorch.org/get-started/locally/\n",
    "For example you should run something like the line below"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install torch==1.5.0+cu101 torchvision==0.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# now run the command below to see if Pytorch detects your GPUs\n",
    "import torch\n",
    "torch.cuda.is_available()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Install the requirements\n",
    "[github source](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GCC\n",
    "About 30 mins."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd /usr/local/src/\n",
    "!sudo wget http://ftp.gnu.org/gnu/gcc/gcc-7.3.0/gcc-7.3.0.tar.xz\n",
    "!sudo tar xvf gcc-7.3.0.tar.xz\n",
    "%cd gcc-7.3.0/\n",
    "!sudo ./contrib/download_prerequisites\n",
    "!sudo ./configure -enable-checking=release -enable-languages=c,c++ -disable-multilib\n",
    "!sudo make -j4\n",
    "!ls /usr/local/bin | grep gcc\n",
    "!sudo make install\n",
    "%cd ~\n",
    "!find /usr/local/src/gcc-7.3.0/ -name \"libstdc++.so*\"\n",
    "%cd /usr/lib64\n",
    "!sudo cp /usr/local/src/gcc-7.3.0/stage1-x86_64-pc-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.24 .\n",
    "!sudo mv libstdc++.so.6 libstdc++.so.6.old\n",
    "!sudo ln -sv libstdc++.so.6.0.24 libstdc++.so.6\n",
    "%cd /home/ec2-user/SageMaker/SGG"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Python libraries\n",
    "Might take 5 to 10 mins to install all the rest. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install ipython scipy h5py"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! pip install ninja yacs cython matplotlib tqdm opencv-python overrides"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ends with `Successfully installed ninja-1.9.0.post1 overrides-3.0.0 yacs-0.1.7`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## install PyCOCO tools (cocoapi)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone https://github.com/cocodataset/cocoapi.git"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! cd cocoapi/PythonAPI; python setup.py build_ext install"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ends with \n",
    "\n",
    "```\n",
    "Finished processing dependencies for pycocotools==2.0\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## install apex\n",
    "it is a PyTorch extension for easy mixed precision and distributed training in Pytorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! git clone https://github.com/NVIDIA/apex.git\n",
    "! cd apex ; python setup.py install"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## install PyTorch Detection (Scene-Graph-Benchmark.pytorch)\n",
    "We change the file name from `Scene-Graph-Benchmark.pytorch` to `Scene`\n",
    "because *ninja* can not handel certain characters in the directory's name\n",
    "([source](https://stackoverflow.com/questions/54569963/error-building-depfile-has-multiple-output-paths-ninja-build-stopped-subcomm ))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python setup.py build develop"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "ends with:\n",
    "\n",
    "\n",
    "```\n",
    "Installed /content/Scene\n",
    "Processing dependencies for maskrcnn-benchmark==0.1\n",
    "Finished processing dependencies for maskrcnn-benchmark==0.1\n",
    "```\n",
    "otherwise you can get:\n",
    "~~~\n",
    "RuntimeError: Error compiling objects for extension\n",
    "~~~\n",
    "\n",
    "\n",
    "The line above might not work for many reasons:\n",
    "* ninja is not installed\n",
    "* the folder name contains crasy characters like space, points\n",
    "* other reasons\n",
    "\n",
    "follow carefully the instructions above to avoid any problem :)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additionnal instructions for Windows:\n",
    "You might incounter this issue https://github.com/facebookresearch/maskrcnn-benchmark/issues/547\n",
    "then you might need to run that first:\n",
    "```\n",
    "set \"VS150COMNTOOLS=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Auxiliary\\Build\"\n",
    "set CMAKE_GENERATOR=Visual Studio 16 2019 Win64\n",
    "set DISTUTILS_USE_SDK=1\n",
    "call \"%VS150COMNTOOLS%\\vcvarsall.bat\" x64 -vcvars_ver=14.11\n",
    "python setup.py build develop\n",
    "call \"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\vcvarsall.bat\"  x64 -vcvars_ver=14.0\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATASET\n",
    "## VG images\n",
    "Download the VG images part1 (9 Gb) part2 (5 Gb)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "! wget https://cs.stanford.edu/people/rak248/VG_100K_2/images2.zip"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Please Extract these images to the directory datasets/vg/VG_100K/ \n",
    "\n",
    "If you want to use other directory, please link it in `DATASETS['VG_stanford_filtered']['img_dir']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGG model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following code does this automatically:\n",
    "\n",
    "Download the [scene graphs](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I) to `Scene/datasets/vg/VG-SGG-with-attri.h5` (144 Mb)\n",
    "\n",
    "or you can edit the path in `DATASETS['VG_stanford_filtered_with_attribute']['roidb_file']` of `maskrcnn_benchmark/config/paths_catelog.py`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install gdown"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# alternatively\n",
    "! gdown \"https://drive.google.com/uc?id=1h2XzeQgJNYgg3q66t1oujofbWvBIYMXG\" -O ./maskrcnn_benchmark/data/datasets/vg/VG-SGG-with-attri.h5\n",
    "# miror link for manual download https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779871&authkey=AA33n7BRpB1xa3I"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pretrained models\n",
    "\n",
    "do not name any directory `checkpoints` with an ``s`` because you will not be able to explore it using jupyter notebook"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir ./checkpoint/pretrained_faster_rcnn/\n",
    "cd ./checkpoint/pretrained_faster_rcnn/\n",
    "gdown \"https://drive.google.com/uc?id=1GoUdVlwZ8ekS7w_aWJ-tcXsx-ULCCjyI\" -O log.txt\n",
    "gdown \"https://drive.google.com/uc?id=1Pj8gfFBouqaKzJVkOV6wsY8GU60z6Nrb\" -O config.yml\n",
    "gdown \"https://drive.google.com/uc?id=1TRT3uX0tbqvIfNeL3bRGzVeqKS8SHtFa\" -O model_final.pth\n",
    "gdown \"https://drive.google.com/uc?id=1Y1SnKGeQCBqGmIpUa8izy2EvUYLyPc89\" -O VG_stanford_filtered_wth_attribute_train_statistics.cache\n",
    "gdown \"https://drive.google.com/uc?id=1_aRGThcciCvg0gFLr9EkhLIE92vEitfP\" -O labels.json\n",
    "gdown \"https://drive.google.com/uc?id=1q6w_tZzhKTx70hgmQ-7Rnlt4EM60MmXp\" -O last_checkpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the links above are dead you can download and extract the files manually following this:\n",
    "\n",
    "- [download the Faster R-CNN model](https://onedrive.live.com/embed?cid=22376FFAD72C4B64&resid=22376FFAD72C4B64%21779870&authkey=AH5CPVb9g5E67iQ),\n",
    "- extract all the files to the directory `./checkpoints/pretrained_faster_rcnn`. \n",
    "\n",
    "To train your own Faster R-CNN model, please follow [the next section](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch#pretrained-models).\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SGDet Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!aws s3 cp s3://datalab2021/gree/causal_motif_sgdet.zip  ./checkpoints"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%cd checkpoints\n",
    "!unzip causal_motif_sgdet.zip\n",
    "%cd .."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Setup done !\n",
    "# Training and Testing\n",
    "## Settings\n",
    "The default settings are under\n",
    "\n",
    "`configs/e2e_relation_X_101_32_8_FPN_1x.yaml` ([see on github](https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch/blob/db02790a60bb9b9f7c270352820968b2f2089469/configs/e2e_relation_X_101_32_8_FPN_1x.yaml#L74))\n",
    "and\n",
    "`maskrcnn_benchmark/config/defaults.py` (todo find link in github)\n",
    "\n",
    "The priority is in this order `command > yaml > defaults.py`\n",
    "\n",
    "* For Predicate Classification (PredCls), we need to set:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True\n",
    "```\n",
    "\n",
    "* For Unbiased-Causal-TDE Model:\n",
    "```\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor\n",
    "```"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Example 1 : (PreCls, Motif Model)\n",
    "### Training Example 1 : (PreCls, Motif Model)\n",
    "\n",
    "`CUDA_VISIBLE_DEVICES=0,1` <-- will use GPU 0 and 1\n",
    "\n",
    "`python -m torch.distributed.launch` <-- will run the script across multiple GPUs\n",
    "\n",
    "`--master_port 10025` <-- the value itself is not important, just use a free port\n",
    "\n",
    "`--nproc_per_node=2` <-- [{num_gpus}](https://docs.fast.ai/distributed.html): this should correspond to the number of gpu you specified up\n",
    "\n",
    "\n",
    "`tools/relation_train_net.py` <-- the script to run by the \"torch.distributed\". Mainly we want to train the model, or resume the training\n",
    "`--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"` <-- Config file for all what we didn't specify\n",
    "`MODEL.ROI_RELATION_HEAD.USE_GT_BOX True ` <-- \n",
    "`MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True ` <-- This means that the ground truth object labels are provided as input to the model.\n",
    "\n",
    "`MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor ` <-- round truth bounding boxes are provided as input to the model.\n",
    "\n",
    "`SOLVER.IMS_PER_BATCH 12` <--        **this number must be divisible by the number of GPUs (2) used.**\n",
    "\n",
    "`TEST.IMS_PER_BATCH 2` <--            **must be equal to the number of GPUs (2) used.**\n",
    "\n",
    "`DTYPE \"float16\" ` <-- \n",
    "\n",
    "`SOLVER.MAX_ITER 50000 ` <-- number of epoch, there is also EarlyStopping implemented\n",
    "\n",
    "`SOLVER.VAL_PERIOD 2000 ` <-- run validation every 2 000 epochs\n",
    "\n",
    "`SOLVER.CHECKPOINT_PERIOD 2000 ` <-- create a checkpoint every 2000 epochs (1 hour or more)\n",
    "\n",
    "`GLOVE_DIR /home/kaihua/glove ` <-- directory where the pretrained word embeddings will be downloaded and stored\n",
    "\n",
    "`MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoint/pretrained_faster_rcnn/model_final.pth ` <-- \n",
    "\n",
    "`OUTPUT_DIR /home/kaihua/checkpoints/motif-precls-exmp` <-- where the model is saved. if the directory is not empty then the training is automatically resumed. So you can for example stop training and add more GPUs\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "SOLVER.BASE_LR 0.08 \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 1 DTYPE \"float16\" \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR ./glove \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR ./checkpoints/causal-motifs-sgdet-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none SOLVER.IMS_PER_BATCH 8 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR ./glove \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR ./checkpoints/causal-motifs-sgdet-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10026 --nproc_per_node=2 tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" MODEL.ROI_RELATION_HEAD.USE_GT_BOX False MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs  SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 GLOVE_DIR ./glove MODEL.PRETRAINED_DETECTOR_CKPT /home/ec2-user/SageMaker/SGG/scene-graph-benchmark/pretrained_faster_rcnn/model_final.pth OUTPUT_DIR ./checkpoints/causal-motifs-sgdet-exmp\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" MODEL.ROI_RELATION_HEAD.USE_GT_BOX True MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 GLOVE_DIR ./glove MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth OUTPUT_DIR ./checkpoints/motif-precls-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test Example 1 : (PreCls, Motif Model)\n",
    "Better use only one GPU for testing\n",
    "~~~\n",
    "CUDA_VISIBLE_DEVICES=0\n",
    "python -m torch.distributed.launch \n",
    "--master_port 10027 \n",
    "--nproc_per_node=1\n",
    "~~~\n",
    "\n",
    "`tools/relation_test_net.py` <-- this line is the only that change\n",
    "\n",
    "~~~\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\"\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \n",
    "~~~\n",
    "`TEST.IMS_PER_BATCH 1` <----------------------------- must be equal to nproc_per_node\n",
    "~~~\n",
    "DTYPE \"float16\" \n",
    "GLOVE_DIR /home/kaihua/glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoints/motif-precls-exmp \n",
    "OUTPUT_DIR checkpoints/motif-precls-exmp\n",
    "~~~"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluation\n",
    "! cd \"Scene/\"; python -m torch.distributed.launch --master_port 10027 --nproc_per_node=8 tools/relation_test_net.py \\\n",
    "--config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL True \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR MotifPredictor \\\n",
    "TEST.IMS_PER_BATCH 32 DTYPE \"float16\" \\\n",
    "GLOVE_DIR glove/ \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT checkpoint/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR checkpoint/motif-precls-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and test Example 2 : (SGCls, Causal, TDE, SUM Fusion, MOTIFS Model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!  python -m torch.distributed.launch --master_port 10026 --nproc_per_node=2 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX True \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none \n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\  \n",
    "SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 2 DTYPE \"float16\" \\ \n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\ \n",
    "GLOVE_DIR ./glove \n",
    "MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth \n",
    "OUTPUT_DIR ./checkpoints/causal-motifs-sgcls-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# evaluation\n",
    "CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10028 --nproc_per_node=1 tools/relation_test_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" MODEL.ROI_RELATION_HEAD.USE_GT_BOX True MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs  TEST.IMS_PER_BATCH 1 DTYPE \"float16\" GLOVE_DIR /home/kaihua/glove MODEL.PRETRAINED_DETECTOR_CKPT /home/kaihua/checkpoints/causal-motifs-sgcls-exmp OUTPUT_DIR /home/kaihua/checkpoints/causal-motifs-sgcls-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train and test Example 3 : (SGDet, Causal, TDE, SUM Fusion, MOTIFS Model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!python \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none SOLVER.IMS_PER_BATCH 8 TEST.IMS_PER_BATCH 1 DTYPE \"float16\" \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR ./glove \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR ./checkpoints/causal-motifs-sgdet02-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10026 --nproc_per_node=1 \\\n",
    "tools/relation_train_net.py --config-file \"configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX False \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False \\\n",
    "MODEL.ROI_RELATION_HEAD.PREDICTOR VCTreePredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE none MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER vctree SOLVER.IMS_PER_BATCH 12 TEST.IMS_PER_BATCH 1 \\\n",
    "DTYPE \"float16\" SOLVER.MAX_ITER 50000 SOLVER.VAL_PERIOD 2000 SOLVER.CHECKPOINT_PERIOD 2000 \\\n",
    "GLOVE_DIR ./glove \\\n",
    "MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/pretrained_faster_rcnn/model_final.pth \\\n",
    "OUTPUT_DIR ./checkpoints/causal-vctree-sgdet03-exmp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_port 10055 --nproc_per_node=1 ./tools/relation_test_net.py --config-file \"./configs/e2e_relation_X_101_32_8_FPN_1x.yaml\" \\\n",
    "MODEL.ROI_RELATION_HEAD.USE_GT_BOX False MODEL.ROI_RELATION_HEAD.USE_GT_OBJECT_LABEL False MODEL.ROI_RELATION_HEAD.PREDICTOR CausalAnalysisPredictor \\\n",
    "MODEL.ROI_RELATION_HEAD.CAUSAL.EFFECT_TYPE TDE MODEL.ROI_RELATION_HEAD.CAUSAL.FUSION_TYPE sum MODEL.ROI_RELATION_HEAD.CAUSAL.CONTEXT_LAYER motifs \\\n",
    "TEST.IMS_PER_BATCH 1 DTYPE \"float16\" GLOVE_DIR ./glove MODEL.PRETRAINED_DETECTOR_CKPT ./checkpoints/causal_motif_sgdet OUTPUT_DIR ./checkpoints/causal_motif_sgdet TEST.CUSTUM_EVAL True \\\n",
    "TEST.CUSTUM_PATH ./custom_images DETECTED_SGG_DIR ./sgdet_output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HS.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "189.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}